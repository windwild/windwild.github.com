---
layout: post
title: "Map Reduce 0.01"
description: ""
category: BigData
tags: [MapReduce, BigData]
---
{% include JB/setup %}
## Map-Reduce 0.01

计划去做数据分析，所以要对大数据处理有点感觉了，所以就搜了一下Google那篇非常著名的Map-Reduce的论文《MapReduce: simplified data processing on large clusters》。

这个论文写的很简单，但是很容易让你了解什么是Map-Reduce，同时介绍了很多Map-Reduce中的机制。

![Map Reduce Flow](http://www.eetindia.co.in/IMAGES/MapReduce.gif)

MapRecude主要的操作就是Map和Reduce，通过这两个操作来处理大规模的数据或者大规模的计算。有的时候一个任务可能需要多次Map-Reduce才能达到目标。

Map-Reduce框架中，主要有三种节点，Master节点、Map节点和Reduce。Master节点控制着任务的分发，Map节点对数据进行Map错做，Reduce节点对数据进行Reduce操作。

以下引用了论文的原文：

-----
> 3.1 Execution Overview
> The map invocations are distributed across multiple machines by auto- matically partitioning the input data into a set of M splits. The input splits can be processed in parallel by different machines. Reduce invo- cations are distributed by partitioning the intermediate key space into R pieces using a partitioning function (e.g., hash(key) mod R). The number of partitions (R) and the partitioning function are specified by the user.

> Figure 1 shows the overall flow of a MapReduce operation in our implementation. When the user program calls the MapReduce func- tion, the following sequence of actions occurs (the numbered labels in Figure 1 correspond to the numbers in the following list).

> 1. The MapReduce library in the user program first splits the input files into M pieces of typically 16-64MB per piece (controllable by the user via an optional parameter). It then starts up many copies of the program on a cluster of machines.
> 2. One of the copies of the program—the master— is special. The rest are workers that are assigned work by the master. There are M map tasks and R reduce tasks to assign. The master picks idle workers and assigns each one a map task or a reduce task.
> 3. A worker who is assigned a map task reads the contents of the corre- sponding input split. It parses key/value pairs out of the input data and passes each pair to the user-defined map function. The intermediate key/value pairs produced by the map function are buffered in memory.
> 4. Periodically, the buffered pairs are written to local disk, partitioned into R regions by the partitioning function. The locations of these buffered pairs on the local disk are passed back to the master who is responsible for forwarding these locations to the reduce workers.
> 5. When a reduce worker is notified by the master about these loca- tions, it uses remote procedure calls to read the buffered data from the local disks of the map workers. When a reduce worker has read all intermediate data for its partition, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The sorting is needed because typically many different keys map to the same reduce task. If the amount of intermediate data is too large to fit in memory, an external sort is used.
> 6. The reduce worker iterates over the sorted intermediate data and for each unique intermediate key encountered, it passes the key and the corresponding set of intermediate values to the user’s reduce func- tion. The output of the reduce function is appended to a final out- put file for this reduce partition.
> 7. When all map tasks and reduce tasks have been completed, the mas- ter wakes up the user program. At this point, the MapReduce call in the user program returns back to the user code.

> After successful completion, the output of the mapreduce execution is available in the R output files (one per reduce task, with file names specified by the user). Typically, users do not need to combine these R output files into one file; they often pass these files as input to another MapReduce call or use them from another distributed application that is able to deal with input that is partitioned into multiple files.

-----
这段介绍的很详细，值得一读。

然后就是Map-Reduce中的一些机制，包括：

* Master节点对Map Reduce节点的控制方式
* 错误处理机制
* 数据本地化机制
* 任务粒度控制
* 预加载任务机制

在最后介绍了两个例子grep和sort。又用Large-scale Indexing的成功，再次强调了Map-reduce 框架强大的特性。

